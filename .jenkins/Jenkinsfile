// Licensed to the Apache Software Foundation (ASF) under one
// or more contributor license agreements.  See the NOTICE file
// distributed with this work for additional information
// regarding copyright ownership.  The ASF licenses this file
// to you under the Apache License, Version 2.0 (the
// "License"); you may not use this file except in compliance
// with the License.  You may obtain a copy of the License at
//
//    https://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing,
// software distributed under the License is distributed on an
// "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
// KIND, either express or implied.  See the License for the
// specific language governing permissions and limitations
// under the License.
//
//
// Jenkins CI declaration.
//
// This file is declarative initially.
// The declarative component describes the pipeline stages and to what CI-agnostic scripts they map to.
// These CI-agnostic scripts are used as an intermediate dockerised layer above the ant build.xml
// The ant build.xml is never invoked directly.
//
// Below the declarative section there is groovy scripting methods for all the logic between
//  the 10k ft declarative view and the CI-agnostic scripts.
//
// This Jenkinsfile is expected to work on any ci-cassandra.a.o clone.
// Functionality that depends upon ASF Infra and the canonical ci-cassandra.a.o setup (e.g. post-commit builds)
//  is required to quietly fail when run on other environments.
//
//
//  Job definitions are still being migrated from (where other CI jobs can also be found):
//    https://github.com/apache/cassandra-builds/blob/trunk/jenkins-dsl/cassandra_job_dsl_seed.groovy
//
//
// Syntax help can be found at https://ci-cassandra.apache.org/pipeline-syntax/
//
// Validate/lint this file using the following command
// `curl -X POST  -F "jenkinsfile=<.jenkins/Jenkinsfile" https://ci-cassandra.apache.org/pipeline-model-converter/validate`

pipeline {
  agent { label 'cassandra' }
  options {
    githubProjectProperty('https://github.com/apache/cassandra')
    parallelsAlwaysFailFast()
    timestamps()
  }
  environment {
    
    JOB_NAME = 'Cassandra-devbranch' // FIXME – remove this

    javaVersionDefault = javaVersionDefault()
    javaVersionsSupported = javaVersionsSupported()
  }
  stages {
    stage('Init') {
      steps {
        cleanWs()
        script { currentBuild.result='SUCCESS' }
      }
    }
    stage('Build') {
      steps {
        buildJob(".build/package-artifacts.sh", "build/apache-cassandra-*.tar.gz,build/apache-cassandra-*.jar,build/apache-cassandra-*.pom")
      }
    }
    stage('Packaging') {
      parallel {
        stage('debian') {
          steps {
            buildJob(".build/package-debian.sh", "build/packages/deb/**")
          }
        }
        stage('redhat') {
          steps {
            buildJob(".build/package-redhat.sh rpm", "build/packages/rpm/**")
          }
        }
        stage('centos7') {
          steps {
            buildJob(".build/package-redhat.sh noboolean", "build/packages/rpm/**")
          }
        }
      }
    }
    stage('Test') {
      parallel {
        stage('stress') {
          steps {
            testJob("stress-test")
          }
        }
        stage('fqltool') {
          steps {
            testJob("fqltool-test")
          }
        }
        stage('units') {
          steps {
            testJob("test")
          }
        }
        stage('long units') {
          steps {
            testJob("long-test")
          }
        }
        stage('burn') {
          steps {
            testJob("test-burn")
          }
        }
        stage('cdc') {
          steps {
            testJob("test-cdc")
          }
        }
        stage('compression') {
          steps {
            testJob("test-compression")
          }
        }
        stage('cqlsh') {
          steps {
            testJob("cqlsh-tests")
          }
        }
      }
    }
    stage('Distributed Test') {
      parallel {
        stage('jvm-dtest') {
          steps {
            testJob("jvm-dtest")
          }
        }
        stage('jvm-dtest-upgrade') {
          steps {
            testJob("jvm-dtest-upgrade")
          }
        }       
        stage('dtest') {
          steps {
            testJob("dtest")
          }
        }
        stage('dtest-large') {
          steps {
            testJob("dtest-large")
          }
        }
        stage('dtest-novnode') {
          steps {
            testJob("dtest-novnode")
          }
        }
        stage('dtest-offheap') {
          steps {
            testJob("dtest-offheap")
          }
        }
        stage('dtest-large-novnode') {
          steps {
            testJob("dtest-large-novnode")
          }
        }
        stage('dtest-upgrade') {
          steps {
            testJob("dtest-upgrade")
          }
        }
      }
    }
    stage('Summary') {
      steps {
        junit testResults: '**/build/test/**/TEST*.xml,**/cqlshlib.xml,**/nosetests.xml', testDataPublishers: [[$class: 'StabilityTestDataPublisher']]
        sendNotifications()
        generateUnifiedTestReport()
        collectConsoleLog()
        copyToNightlies('console.log.xz,TESTS-TestSuites.xml.xz')
      }
    }
  }
}

////
//// scripting support ////
////

def javaVersionDefault() {
  sh (returnStdout: true, script: 'grep \'property\\s*name=\"java.default\"\' build.xml | sed -ne \'s/.*value=\"\\([^\"]*\\)\".*/\\1/p\'').trim()
}

def javaVersionsSupported() {
  sh (returnStdout: true, script: 'grep \'property\\s*name=\"java.supported\"\' build.xml | sed -ne \'s/.*value=\"\\([^\"]*\\)\".*/\\1/p\'').trim()
}

def isPostCommit() {
  return "${GIT_URL}".contains("apache/cassandra")
}

def buildJob(build_script, toCopy) {
  def archs = ['cassandra', 'cassandra-arm64']
  def jdks = ['11']// FIXME – use next line instead, when builds work with jdk17
  // FIXME //def jdks = "${javaVersionsSupported}".split(/,/, -1)
  def builds_per_arch = [:]
  for (a in archs) {
    def arch = a
    builds_per_arch[arch] = {
      def builds_per_jdk = [:]
      for (j in jdks) {
        def jdk = j
        builds_per_jdk[jdk] = { buildAxis(build_script, toCopy, arch, jdk) }
      }
      parallel(builds_per_jdk)
    }
  }
  parallel(builds_per_arch)
}

def buildAxis(build_script, toCopy, arch, jdk) {
  node(arch) {
    cleanWs()
    checkout scm
    tool type: 'jdk', name: "jdk_${jdk}_latest"
    def statusCode = 0, attempt = 1
    retry(2) {
      if (attempt > 1) { sleep(60 * attempt) }
      def build_script_safe_name = "${build_script}".replace(".build/", "").replace(".", "_").replace(" ", "_")
      def logfile = "${JOB_NAME}_${BUILD_NUMBER}_${build_script_safe_name}_jdk${jdk}_${arch}_attempt_${attempt}.log"
      try {
        printTestEnv("${JOB_NAME}-${build_name}-${NODE_NAME}_attempt_${attempt}")
        echo "Executing `${build_script} ${jdk} 2>&1 | tee ${logfile}` on ${NODE_NAME}"
        statusCode = sh returnStatus:true, script:"${build_script} ${jdk} 2>&1 | tee ${logfile}"
        if (".build/package-artifacts.sh" == build_script) {
          stash name: "${arch}_${jdk}", includes: "build/**/*.jar", excludes: "build/dist/**"
        }
      } finally {
        attempt = attempt + 1
        sh "xz -f *_attempt_*.log"
        if (0 != statusCode) { toCopy = "" }
        copyToNightlies("*_attempt_*.log.xz,${toCopy}", "${build_script_safe_name}/jdk${jdk}/${arch}")
        cleanAgent(build_script)
        if (0 != statusCode) { 
          currentBuild.result = 'FAILURE'
          error("'${build_script} ${jdk}' on ${NODE_NAME} failed!") 
        }
      }
    }
  }
}

def testJob(build_name) {
  def attempt = 1
  retry(2) {
    if (attempt > 1) { sleep(60 * attempt) }
    try {
      // TODO – rewrite to dynamic matrix build (like buildJob(..))
      build_result = build job: "${JOB_NAME}-${build_name}", propagate: false
    } finally {
      attempt = attempt + 1
      copyTestResults("${JOB_NAME}-${build_name}", build_result.getNumber())
    }
  }
  if (build_result.result != 'SUCCESS') unstable("${build_name} failures")
  if (build_result.result == 'ABORTED' && currentBuild.result != 'FAILURE') currentBuild.result='ABORTED'
  if (build_result.result == 'FAILURE') currentBuild.result='FAILURE'
  return build_result
}

def copyToNightlies(sourceFiles, remoteDirectory='') {
  def remotePath = remoteDirectory.startsWith("cassandra/") ? "${remoteDirectory}" : "cassandra/${JOB_NAME}/${BUILD_NUMBER}/${remoteDirectory}"
  def attempt = 1
  retry(9) {
    if (attempt > 1) { sleep(60 * attempt) }
    sshPublisher(
      continueOnError: true, failOnError: true,
      publishers: [
        sshPublisherDesc(
         configName: "Nightlies",
         transfers: [ sshTransfer( sourceFiles: sourceFiles, remoteDirectory: remotePath) ]
         )
      ])
  }
  echo "archived to https://nightlies.apache.org/${remotePath}"
}

/**
 * This is intended to be manually inspected during situations where tests
 * are flaky or otherwise failing due to what we expect to be environment
 * issues. As such we're optimizing format for human consumption.
 */
def printTestEnv(build_label) {
  echo "-----------------------------------------------------"
  echo "Printing test environment details for: ${build_label}"
  echo "-----------------------------------------------------"
  echo "Host name: ${runShell("hostname")}"
  echo "IP: ${runShell("hostname -I")}"

  echo "--------------Agent / Node paramenters --------------"
  echo "CPU environment detail: ${runShell("lscpu")}"
  echo "Total memory on machine: ${runShell("grep MemTotal /proc/meminfo")}"
  echo "Storage details: ${runShell("lshw -class storage")}"
  echo "Zombie process check: ${runShell("ps axo pid=,stat= | awk '\$2~/^Z/ { print }")}"
  echo "Docker cache: ${runShell("docker image ls -a")}"
  echo "Disk usage / free: ${runShell("df -h")}"
  echo "Inode usage: ${runShell("df -i")}"
  echo "All running and stopped containers: ${runShell("docker container ls -a")}"
  echo "---------- Container parameters ---------------------"
  echo "Kernel version: ${runShell("uname -a")}"
  echo "Release version: ${runShell("lsb_release -icr")}"
  echo "Memory usage in container: ${runShell("cat /sys/fs/cgroup/memory/memory.limit_in_bytes")}"
  echo "CPU usage in container: ${runShell("cat /sys/fs/cgroup/cpu/cpuacct.usage")}"
  echo "CPU count available to container: ${runShell("nproc")}"

}

/**
 * Simple convenience wrapper to make running and capturing return from a shell script cleaner and "inlineable"
 * @param command shell script to run
 * @return stringified return from the run command's stdout
 */
def runShell(command) {
  return sh (
          script: "${command}",
          returnStdout: true).trim()

}

def cleanAgent(build_name) {
  def maxJobHours = 12
  echo "Cleaning project, processes, docker for '${build_name}' on ${NODE_NAME}…" ;
  sh """
      git clean -qxdff -e build/test/jmh-result.json || true;
      if pgrep -xa docker || pgrep -af "cassandra-builds/build-scripts" ; then docker system prune --all --force --filter "until=${maxJobHours}h" || true ; else  docker system prune --all --force --volumes || true ;  fi;
     """
}

//  CASSANDRA-18130
def saveAgentReport(build_name) {
  // 
  // echo "Updating disk usage report…";
  // sh """
  //     ( echo "----" ;
  //     echo \$(date) ;
  //     echo "${JOB_NAME} ${BUILD_NUMBER} ${build_name}" ;
  //     du -xm / 2>/dev/null | sort -rn | head -n 30 ;
  //     df -h ) | tee -a \$(date +"%Y%m%d%H%M")-disk-usage-stats.txt
  //   """
  //   copyToNightlies("*-disk-usage-stats.txt", "cassandra/agents/${NODE_NAME}/disk-usage/")
  //   sh 'rm *-disk-usage-stats.txt'
}

//////
////// scripting support for summary ////
//////

def generateUnifiedTestReport() {
  sh "ant -f .jenkins/cassandra-test-report.xml"
  sh "xz -f TESTS-TestSuites.xml"

  // also print SHAs // TODO – remove when all tests are dynamic/in-tree
  sh """
    if [ \$(find . -type f -name "*.head" -exec cat {} \\; | grep ") cassandra" | awk -F') cassandra' '{print \$2}' | sort -u | sed -n '\$=') = "3" ]; then
      echo "The folllowing SHAs were consistently used in all jobs in the pipeline…"
      find . -type f -name "*.head" -exec cat {} \\; | grep ") cassandra" | awk -F') cassandra' '{print "cassandra"\$2}' | sort -u
    else
      echo "\$(find . -type f -name "*.head" -exec cat {} \\; | grep ") cassandra" | awk -F') cassandra' '{print \$2}' | sort -u | sed -n '\$=') different SHAs were used in different jobs in the pipeline. Printing everything…"
      find . -type f -name "*.head" -exec cat {} \\;
    fi
    """
}

def collectConsoleLog() {
  sh "wget --retry-connrefused --waitretry=1 \"\${BUILD_URL}/timestamps/?time=HH:mm:ss&timeZone=UTC&appendLog\" -qO console.log || echo wget failed"
  sh "xz -f console.log"
}

def copyTestResults(build_name, build_number) {
  try {
    step([$class: 'CopyArtifact',
            projectName: "${build_name}",
            optional: true,
            fingerprintArtifacts: true,
            selector: specific("${build_number}"),
            target: build_name]);
  } catch (Exception ex) {
    echo 'Exception occurred getting test results for  ' + build_name + '#' + build_number + ex.toString()
  }
}

def sendNotifications() {
  if (isPostCommit()) {
    // the following is expected only to work on ci-cassandra.apache.org
    try {
      script {
        changes = formatChangeLogChanges(currentBuild.changeSets)
        echo "changes: ${changes}"
      }
      slackSend channel: '#cassandra-builds', message: ":apache: <${BUILD_URL}|${currentBuild.fullDisplayName}> completed: ${currentBuild.result}. <https://github.com/apache/cassandra/commit/${GIT_COMMIT}|${GIT_COMMIT}>\n${changes}"
      emailext to: 'builds@cassandra.apache.org', subject: "Build complete: ${currentBuild.fullDisplayName} [${currentBuild.result}] ${GIT_COMMIT}", presendScript: 'msg.removeHeader("In-Reply-To"); msg.removeHeader("References")', body: emailContent()
    } catch (Exception ex) {
      echo 'failed to send notifications  ' + ex.toString()
    }
  }
}

def formatChangeLogChanges(changeLogSets) {
  def result = ''
  for (int i = 0; i < changeLogSets.size(); i++) {
    def entries = changeLogSets[i].items
    for (int j = 0; j < entries.length; j++) {
      def entry = entries[j]
      result = result + "${entry.commitId} by ${entry.author} on ${new Date(entry.timestamp)}: ${entry.msg}\n"
    }
  }
  return result
}

def emailContent() {
  return '''
  -------------------------------------------------------------------------------
  Build ${ENV,var="JOB_NAME"} #${BUILD_NUMBER} ${BUILD_STATUS}
  URL: ${BUILD_URL}
  -------------------------------------------------------------------------------
  Changes:
  ${CHANGES}
  -------------------------------------------------------------------------------
  Failed Tests:
  ${FAILED_TESTS,maxTests=500,showMessage=false,showStack=false}
  -------------------------------------------------------------------------------
  For complete test report and logs see https://nightlies.apache.org/cassandra/${JOB_NAME}/${BUILD_NUMBER}/
  '''
}
